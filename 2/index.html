<!DOCTYPE html>
<html>
<head>
    <title>Project 2: Fun with Filters and Frequencies!</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }
        
        h1, h2, h3 {
            color: #2c3e50;
            margin-top: 30px;
        }
        
        h1 {
            text-align: center;
            border-bottom: 2px solid #2c3e50;
            padding-bottom: 10px;
        }
        
        .container {
            background-color: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin-bottom: 30px;
        }
        
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        .image-comparison {
            display: flex;
            justify-content: space-between;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        
        .image-comparison > div {
            flex: 0 1 48%;
            margin-bottom: 20px;
        }
        
        .image-comparison img {
            width: 100%;
            max-width: 400px;
            max-height: 300px;
            object-fit: contain;
        }
        
        .image-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        
        .image-grid > div {
            text-align: center;
        }
        
        .image-grid img {
            width: 100%;
            max-width: 300px;
        }
        
        .caption {
            text-align: center;
            font-style: italic;
            margin: 10px 0;
            color: #666;
        }
        
        pre {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            font-family: 'Fira Code', 'Courier New', Courier, monospace;
            font-size: 14px;
            line-height: 1.4;
            overflow-x: auto;
            margin: 20px 0;
            border-left: 4px solid #2c3e50;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        pre code {
            background: none;
            padding: 0;
            border-radius: 0;
            font-size: inherit;
        }
        
        code {
            background-color: #f8f9fa;
            padding: 2px 5px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
        }
        
        .filter-display {
            display: flex;
            justify-content: space-around;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        
        .filter-display > div {
            text-align: center;
            margin: 10px;
        }
        
        .filter-display img {
            width: 150px;
            height: 150px;
            object-fit: contain;
        }
        
        .threshold-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        
        .threshold-grid > div {
            text-align: center;
        }
        
        .threshold-grid img {
            width: 100%;
            max-width: 200px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Project 2: Fun with Filters and Frequencies!</h1>
        
        <h2>Overview</h2>
        <p>
            This project implements fundamental image processing techniques including 2D convolution, edge detection, frequency domain filtering, hybrid images, and multiresolution blending. The work demonstrates core concepts in computer vision through practical implementation and analysis of filtering operations and frequency manipulation.
        </p>

        <h2>Part 1: Fun with Filters</h2>

        <h3>Part 1.1: Convolutions from Scratch</h3>
        <p>
            This section implements 2D convolution using both four-loop and two-loop approaches with zero-padding. Performance and accuracy are compared against the built-in <code>scipy.signal.convolve2d</code> function.
        </p>

        <pre><code class="language-python">def convolve2d_4loops(image, kernel):
    # Get dimensions
    img_h, img_w = image.shape
    ker_h, ker_w = kernel.shape

    # Flip kernel
    flipped_kernel = np.flip(kernel)
    
    # Calculate padding
    pad_h = ker_h - 1
    pad_w = ker_w - 1
    
    # Add zero padding
    padded_img = np.zeros((img_h + 2*pad_h, img_w + 2*pad_w))
    padded_img[pad_h:-pad_h if pad_h > 0 else None, pad_w:-pad_w if pad_w > 0 else None] = image
    
    # Output size for full convolution
    output_h = img_h + ker_h - 1
    output_w = img_w + ker_w - 1
    output = np.zeros((output_h, output_w))
    
    # Perform convolution with four loops
    for i in range(output_h):
        for j in range(output_w):
            for ki in range(ker_h):
                for kj in range(ker_w):
                    output[i, j] += flipped_kernel[ki, kj] * padded_img[i + ki, j + kj]

    return output

def convolve2d_2loops(image, kernel):
    """
    2D convolution with full padding using only 2 loops (vectorized inner operations)
    """
    # Get dimensions
    img_h, img_w = image.shape
    ker_h, ker_w = kernel.shape
    
    # Flip kernel
    flipped_kernel = np.flip(kernel)
    
    # Calculate padding for FULL convolution
    pad_h = ker_h - 1
    pad_w = ker_w - 1
    
    # Add zero padding
    padded_img = np.zeros((img_h + 2*pad_h, img_w + 2*pad_w))
    padded_img[pad_h:-pad_h if pad_h > 0 else None, pad_w:-pad_w if pad_w > 0 else None] = image
    
    # Output size for full convolution
    output_h = img_h + ker_h - 1
    output_w = img_w + ker_w - 1
    output = np.zeros((output_h, output_w))
    
    # Perform convolution with two loops
    for i in range(output_h):
        for j in range(output_w):
            # Extract the image patch and compute dot product with flipped kernel
            patch = padded_img[i:i+ker_h, j:j+ker_w]
            output[i, j] = np.sum(patch * flipped_kernel)
    
    return output</code></pre>

        <p>
            Performance comparison on grayscale portrait image with 9x9 box filter:
        </p>
        <ul>
            <li><strong>4-loop implementation:</strong> 7.70 seconds</li>
            <li><strong>2-loop implementation:</strong> 1.76 seconds</li>
            <li><strong>Built-in scipy function:</strong> 0.80 seconds</li>
        </ul>

        <p>
            All implementations produce identical results within floating point precision, validating the correctness of the custom implementations.
        </p>

        <h4>Filter Results on Grayscale Portrait</h4>
        <div class="image-grid">
            <div>
                <img src="greyscale_portrait.png" alt="Original grayscale portrait">
                <p class="caption">Original Image</p>
            </div>
            <div>
                <img src="results/greyscale_portrait_box_filtered.png" alt="Box filtered portrait">
                <p class="caption">Box Filter</p>
            </div>
            <div>
                <img src="results/greyscale_portrait_Dx_filtered.png" alt="Dx filtered portrait">
                <p class="caption">Dx Filter</p>
            </div>
            <div>
                <img src="results/greyscale_portrait_Dy_filtered.png" alt="Dy filtered portrait">
                <p class="caption">Dy Filter</p>
            </div>
        </div>

        <h3>Part 1.2: Finite Difference Operator</h3>
        <p>
            This section computes partial derivatives using finite difference operators D_x = [1, 0, -1] and D_y = [[1], [0], [-1]], calculates gradient magnitude, and generates edge images through binarization with threshold selection.
        </p>


        <div class="image-grid">
            <div>
                <img src="cameraman.png" alt="Original cameraman">
                <p class="caption">Original Cameraman Image</p>
            </div>
            <div>
                <img src="results/cameraman_Dx.png" alt="Dx derivative">
                <p class="caption">Partial Derivative in X</p>
            </div>
            <div>
                <img src="results/cameraman_Dy.png" alt="Dy derivative">
                <p class="caption">Partial Derivative in Y</p>
            </div>
            <div>
                <img src="results/cameraman_grad_mag_80.png" alt="Gradient magnitude">
                <p class="caption">Gradient Magnitude (threshold=80)</p>
            </div>
        </div>

        <h4>Threshold Selection</h4>
        <p>
            Threshold selection affects edge detection quality. A threshold of 80 provides optimal balance between noise suppression and edge preservation:
        </p>

        <div class="threshold-grid">
            <div>
                <img src="results/cameraman_grad_mag_30.png" alt="Threshold 30">
                <p class="caption">Threshold = 30 (too noisy)</p>
            </div>
            <div>
                <img src="results/cameraman_grad_mag_60.png" alt="Threshold 60">
                <p class="caption">Threshold = 60</p>
            </div>
            <div>
                <img src="results/cameraman_grad_mag_80.png" alt="Threshold 80">
                <p class="caption">Threshold = 80 (optimal)</p>
            </div>
            <div>
                <img src="results/cameraman_grad_mag_100.png" alt="Threshold 100">
                <p class="caption">Threshold = 100 (too sparse)</p>
            </div>
        </div>

        <h3>Part 1.3: Derivative of Gaussian (DoG) Filter</h3>
        <p>
            Raw finite difference operators produce noisy results. This section applies Gaussian smoothing before derivative computation to reduce noise and improve edge detection quality.
        </p>


        <h4>Filter Visualization</h4>
        <div class="filter-display">
            <div>
                <img src="results/gaussian_2d_filter.png" alt="2D Gaussian filter">
                <p class="caption">2D Gaussian Filter</p>
            </div>
            <div>
                <img src="results/DoG_x_filter.png" alt="DoG X filter">
                <p class="caption">DoG X Filter</p>
            </div>
            <div>
                <img src="results/DoG_y_filter.png" alt="DoG Y filter">
                <p class="caption">DoG Y Filter</p>
            </div>
        </div>

        <h4>Comparison: Sequential vs Single Convolution</h4>
        <div class="image-comparison">
            <div>
                <img src="results/cameraman_smooth_grad_mag.png" alt="Sequential convolution result">
                <p class="caption">Sequential Convolution<br>(Gaussian → Derivative)</p>
            </div>
            <div>
                <img src="results/cameraman_dog_grad_mag.png" alt="DoG convolution result">
                <p class="caption">Single Convolution<br>(Derivative of Gaussian)</p>
            </div>
        </div>

        <p>
            <strong>Results:</strong> The DoG approach significantly reduces noise compared to raw finite difference operators. Sequential and single convolution methods produce identical results, confirming the associative property of convolution.
        </p>

        <h2>Part 2: Fun with Frequencies!</h2>

        <h3>Part 2.1: Image Sharpening</h3>
        <p>
            This section implements unsharp masking for image sharpening. The technique subtracts a low-pass filtered version from the original image to extract high frequencies, then adds amplified high frequencies back to enhance perceived sharpness.
        </p>

        <p>
            The unsharp mask filter can be expressed as: <strong>f_sharp = f + α(f - f_blurred) = (1 + α)f - αf_blurred</strong>
        </p>


        <h4>Sharpening Results on Taj Mahal</h4>
        <div class="image-grid">
            <div>
                <img src="taj.jpg" alt="Original Taj">
                <p class="caption">Original Image</p>
            </div>
            <div>
                <img src="results/taj_0.5_unsharp_mask.png" alt="Taj alpha=0.5">
                <p class="caption">α = 0.5 (subtle sharpening)</p>
            </div>
            <div>
                <img src="results/taj_2_unsharp_mask.png" alt="Taj alpha=2">
                <p class="caption">α = 2 (moderate sharpening)</p>
            </div>
            <div>
                <img src="results/taj_4_unsharp_mask.png" alt="Taj alpha=4">
                <p class="caption">α = 4 (strong sharpening)</p>
            </div>
        </div>

        <h4>Sharpening Results on Girl</h4>
        <div class="image-grid">
            <div>
                <img src="girl.jpg" alt="Original girl">
                <p class="caption">Original Image</p>
            </div>
            <div>
                <img src="results/girl_1_unsharp_mask.png" alt="Girl alpha=1">
                <p class="caption">α = 1 (moderate sharpening)</p>
            </div>
            <div>
                <img src="results/girl_2_unsharp_mask.png" alt="Girl alpha=2">
                <p class="caption">α = 2 (strong sharpening)</p>
            </div>
            <div>
                <img src="results/girl_4_unsharp_mask.png" alt="Girl alpha=4">
                <p class="caption">α = 4 (very strong sharpening)</p>
            </div>
        </div>

        <h4>Evaluation: Sharp → Blur → Sharpen</h4>
        <p>
            Unsharp masking effectiveness is evaluated by artificially blurring a sharp image (bird) and attempting to restore sharpness:
        </p>

        <div class="image-grid">
            <div>
                <img src="bird.jpg" alt="Original sharp bird">
                <p class="caption">Original Sharp Image</p>
            </div>
            <div>
                <img src="results/bird_blurred.png" alt="Artificially blurred bird">
                <p class="caption">Artificially Blurred</p>
            </div>
            <div>
                <img src="results/bird_blurred_unsharp_mask.png" alt="Re-sharpened bird">
                <p class="caption">After Unsharp Masking (α = 4)</p>
            </div>
        </div>

        <p>
            <strong>Results:</strong> Unsharp masking enhances perceived sharpness by emphasizing edges and high-frequency details but cannot recover information lost during blurring. The re-sharpened image shows enhanced edges but lacks the fine detail of the original, demonstrating the fundamental limitation that frequency domain processing cannot create information not originally present.
        </p>

        <h3>Part 2.2: Hybrid Images</h3>
        <p>
            This section implements hybrid images. Hybrid images combine high-frequency components from one image with low-frequency components from another, creating images with different interpretations at varying viewing distances.
        </p>

        <h4>Derek + Nutmeg Hybrid (Detailed Process)</h4>
        <p>
            The complete hybrid image creation process is demonstrated using Derek and Nutmeg images:
        </p>

        <div class="image-comparison">
            <div>
                <img src="DerekPicture.jpg" alt="Original Derek">
                <p class="caption">Original Derek Image</p>
            </div>
            <div>
                <img src="nutmeg.jpg" alt="Original Nutmeg">
                <p class="caption">Original Nutmeg Image</p>
            </div>
        </div>

        <h5>Filtering Process</h5>
        <div class="image-comparison">
            <div>
                <img src="results/05_low_frequencies_derek.png" alt="Low frequencies">
                <p class="caption">Low Frequencies (Nutmeg)<br>Gaussian filtered for distant viewing</p>
            </div>
            <div>
                <img src="results/06_high_frequencies_derek.png" alt="High frequencies">
                <p class="caption">High Frequencies (Derek)<br>High-pass filtered for close viewing</p>
            </div>
        </div>

        <h5>Final Result</h5>
        <div style="text-align: center; margin: 20px 0;">
            <img src="results/07_hybrid_final_derek.png" alt="Hybrid final" style="max-width: 400px; max-height: 300px; object-fit: contain;">
            <p class="caption">Final Hybrid Image<br>(Nutmeg from far, Derek from close)</p>
        </div>

        <h5>Frequency Analysis</h5>
        <div style="text-align: center; margin: 20px 0;">
            <img src="results/09_frequency_analysis_derek.png" alt="Frequency analysis" style="max-width: 100%; height: auto;">
            <p class="caption">Frequency Domain Analysis<br>Log magnitude of Fourier transforms</p>
        </div>

        <p>
            <strong>Process Summary:</strong> Nutmeg's image undergoes low-pass filtering to retain smooth, low-frequency information for distant viewing. Derek's image is high-pass filtered to extract fine details for close viewing. The hybrid combination produces an image appearing as Nutmeg from distance and Derek when viewed closely.
        </p>

        <h4>Additional Hybrid Images</h4>
        
        <h5>Bear + Dog Hybrid</h5>
        <div class="image-grid">
            <div>
                <img src="bear.jpeg" alt="Original Bear">
                <p class="caption">Original Bear</p>
            </div>
            <div>
                <img src="dog.jpeg" alt="Original Dog">
                <p class="caption">Original Dog</p>
            </div>
            <div>
                <img src="results/07_hybrid_final_bog.png" alt="Bear Dog hybrid">
                <p class="caption">Hybrid Result<br>(Bear from far, Dog from close)</p>
            </div>
        </div>

        <h5>Penguin + Doctor Hybrid</h5>
        <div class="image-grid">
            <div>
                <img src="penguin.jpeg" alt="Original Penguin">
                <p class="caption">Original Penguin</p>
            </div>
            <div>
                <img src="doctor.jpeg" alt="Original Doctor">
                <p class="caption">Original Doctor</p>
            </div>
            <div>
                <img src="results/07_hybrid_final_pengtor.png" alt="Penguin Doctor hybrid">
                <p class="caption">Hybrid Result<br>(Penguin from far, Doctor from close)</p>
            </div>
        </div>

        <h3>Part 2.3: Gaussian and Laplacian Stacks</h3>
        <p>
            This section implements Gaussian and Laplacian stacks without downsampling. Stacks maintain original image dimensions at each level, enabling precise multi-resolution blending. The Gaussian stack applies successive filtering while the Laplacian stack captures differences between consecutive Gaussian levels.
        </p>

        <p>
            <strong>Implementation:</strong> Unlike pyramids, stacks preserve image dimensions at all levels, preventing resolution loss during multi-resolution processing.
        </p>

        <h3>Part 2.4: Multiresolution Blending</h3>
        <p>
            This section implements multiresolution blending using Gaussian and Laplacian stacks. The method blends images at multiple frequency scales, creating seamless transitions impossible with simple pixel averaging.
        </p>

        <h4>Apple + Orange Blend (Oraple)</h4>
        <p>
            Implementation of the apple-orange blend with vertical seam:
        </p>

        <div class="image-comparison">
            <div>
                <img src="apple.jpeg" alt="Original apple">
                <p class="caption">Original Apple</p>
            </div>
            <div>
                <img src="orange.jpeg" alt="Original orange">
                <p class="caption">Original Orange</p>
            </div>
        </div>

        <div class="image-comparison">
            <div>
                <img src="results/oraple_stack.png" alt="Oraple process visualization">
                <p class="caption">Multiresolution Blending Process<br>Showing Laplacian stacks and mask levels</p>
            </div>
            <div>
                <img src="results/oraple_blend.png" alt="Final oraple">
                <p class="caption">Final Oraple Result<br>Seamless apple-orange blend</p>
            </div>
        </div>


        <p>
            <strong>Algorithm Overview:</strong>
        </p>
        <ol>
            <li>Create Gaussian stacks for both input images and the blending mask</li>
            <li>Generate Laplacian stacks from the Gaussian stacks</li>
            <li>Blend corresponding levels</li>
            <li>Reconstruct final image by summing all blended Laplacian levels</li>
        </ol>

        <p>
            <strong>Key Advantages:</strong> The multiresolution approach blends different frequency components at appropriate scales. Low frequencies blend smoothly across the entire transition region, while high frequencies maintain sharp details where needed. This creates natural-looking seams.
        </p>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</body>
</html>
