<!DOCTYPE html>
<html>
<head>
    <title>Project 2: Fun with Filters and Frequencies!</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism.min.css" rel="stylesheet">
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }
        
        h1, h2, h3 {
            color: #2c3e50;
            margin-top: 30px;
        }
        
        h1 {
            text-align: center;
            border-bottom: 2px solid #2c3e50;
            padding-bottom: 10px;
        }
        
        .container {
            background-color: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin-bottom: 30px;
        }
        
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        .image-comparison {
            display: flex;
            justify-content: space-between;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        
        .image-comparison > div {
            flex: 0 1 48%;
            margin-bottom: 20px;
        }
        
        .image-comparison img {
            width: 100%;
        }
        
        .image-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        
        .image-grid > div {
            text-align: center;
        }
        
        .image-grid img {
            width: 100%;
            max-width: 300px;
        }
        
        .caption {
            text-align: center;
            font-style: italic;
            margin: 10px 0;
            color: #666;
        }
        
        pre {
            background-color: #f8f9fa;
            padding: 20px;
            border-radius: 8px;
            font-family: 'Fira Code', 'Courier New', Courier, monospace;
            font-size: 14px;
            line-height: 1.4;
            overflow-x: auto;
            margin: 20px 0;
            border-left: 4px solid #2c3e50;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        pre code {
            background: none;
            padding: 0;
            border-radius: 0;
            font-size: inherit;
        }
        
        code {
            background-color: #f8f9fa;
            padding: 2px 5px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
        }
        
        .filter-display {
            display: flex;
            justify-content: space-around;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        
        .filter-display > div {
            text-align: center;
            margin: 10px;
        }
        
        .filter-display img {
            width: 150px;
            height: 150px;
            object-fit: contain;
        }
        
        .threshold-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 15px;
            margin: 20px 0;
        }
        
        .threshold-grid > div {
            text-align: center;
        }
        
        .threshold-grid img {
            width: 100%;
            max-width: 200px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Project 2: Fun with Filters and Frequencies!</h1>
        
        <h2>Overview</h2>
        <p>
            This project explores the fascinating world of 2D convolutions and frequency domain processing. We'll build intuitions about filtering operations by implementing convolutions from scratch, working with finite difference operators, and experimenting with frequency manipulation techniques for image sharpening.
        </p>

        <h2>Part 1: Fun with Filters</h2>
        <p>
            In this part, we build intuitions about 2D convolutions and filtering, starting with the humble finite difference as our filter in the x and y directions.
        </p>

        <h3>Part 1.1: Convolutions from Scratch!</h3>
        <p>
            First, let's implement 2D convolution with both four loops and two loops, including proper padding with zero fill values. We'll compare our implementations with the built-in <code>scipy.signal.convolve2d</code> function.
        </p>

        <pre><code class="language-python">def convolve2d_4loops(image, kernel):
    # Get dimensions
    img_h, img_w = image.shape
    ker_h, ker_w = kernel.shape

    # Flip kernel
    flipped_kernel = np.flip(kernel)
    
    # Calculate padding
    pad_h = ker_h - 1
    pad_w = ker_w - 1
    
    # Add zero padding
    padded_img = np.zeros((img_h + 2*pad_h, img_w + 2*pad_w))
    padded_img[pad_h:-pad_h if pad_h > 0 else None, pad_w:-pad_w if pad_w > 0 else None] = image
    
    # Output size for full convolution
    output_h = img_h + ker_h - 1
    output_w = img_w + ker_w - 1
    output = np.zeros((output_h, output_w))
    
    # Perform convolution with four loops
    for i in range(output_h):
        for j in range(output_w):
            for ki in range(ker_h):
                for kj in range(ker_w):
                    output[i, j] += flipped_kernel[ki, kj] * padded_img[i + ki, j + kj]

    return output

def convolve2d_2loops(image, kernel):
    """
    2D convolution with full padding using only 2 loops (vectorized inner operations)
    """
    # Get dimensions
    img_h, img_w = image.shape
    ker_h, ker_w = kernel.shape
    
    # Flip kernel
    flipped_kernel = np.flip(kernel)
    
    # Calculate padding for FULL convolution
    pad_h = ker_h - 1
    pad_w = ker_w - 1
    
    # Add zero padding
    padded_img = np.zeros((img_h + 2*pad_h, img_w + 2*pad_w))
    padded_img[pad_h:-pad_h if pad_h > 0 else None, pad_w:-pad_w if pad_w > 0 else None] = image
    
    # Output size for full convolution
    output_h = img_h + ker_h - 1
    output_w = img_w + ker_w - 1
    output = np.zeros((output_h, output_w))
    
    # Perform convolution with two loops
    for i in range(output_h):
        for j in range(output_w):
            # Extract the image patch and compute dot product with flipped kernel
            patch = padded_img[i:i+ker_h, j:j+ker_w]
            output[i, j] = np.sum(patch * flipped_kernel)
    
    return output</code></pre>

        <p>
            Performance comparison on a grayscale portrait image with different filters:
        </p>
        <ul>
            <li><strong>4-loop implementation:</strong> 1.52 seconds</li>
            <li><strong>2-loop implementation:</strong> 1.82 seconds</li>
            <li><strong>Built-in scipy function:</strong> 0.011 seconds</li>
        </ul>

        <p>
            All implementations produce identical results (within floating point precision), confirming our implementations are correct.
        </p>

        <h4>Filter Results on Grayscale Portrait</h4>
        <div class="image-grid">
            <div>
                <img src="greyscale_portrait.png" alt="Original grayscale portrait">
                <p class="caption">Original Image</p>
            </div>
            <div>
                <img src="results/greyscale_portrait_box_filtered.png" alt="Box filtered portrait">
                <p class="caption">Box Filter (3x3 averaging)</p>
            </div>
            <div>
                <img src="results/greyscale_portrait_Dx_filtered.png" alt="Dx filtered portrait">
                <p class="caption">Dx Filter (horizontal edges)</p>
            </div>
            <div>
                <img src="results/greyscale_portrait_Dy_filtered.png" alt="Dy filtered portrait">
                <p class="caption">Dy Filter (vertical edges)</p>
            </div>
        </div>

        <h3>Part 1.2: Finite Difference Operator</h3>
        <p>
            Now we'll compute partial derivatives of the cameraman image using finite difference operators D_x = [1, 0, -1] and D_y = [[1], [0], [-1]], then compute the gradient magnitude and create edge images through binarization.
        </p>


        <div class="image-grid">
            <div>
                <img src="cameraman.png" alt="Original cameraman">
                <p class="caption">Original Cameraman Image</p>
            </div>
            <div>
                <img src="results/cameraman_Dx.png" alt="Dx derivative">
                <p class="caption">Partial Derivative in X</p>
            </div>
            <div>
                <img src="results/cameraman_Dy.png" alt="Dy derivative">
                <p class="caption">Partial Derivative in Y</p>
            </div>
            <div>
                <img src="results/cameraman_grad_mag_80.png" alt="Gradient magnitude">
                <p class="caption">Gradient Magnitude (threshold=80)</p>
            </div>
        </div>

        <h4>Threshold Selection</h4>
        <p>
            Different threshold values produce different edge detection results. A threshold of 80 was found to provide the best balance between noise suppression and edge preservation:
        </p>

        <div class="threshold-grid">
            <div>
                <img src="results/cameraman_grad_mag_30.png" alt="Threshold 30">
                <p class="caption">Threshold = 30 (too noisy)</p>
            </div>
            <div>
                <img src="results/cameraman_grad_mag_60.png" alt="Threshold 60">
                <p class="caption">Threshold = 60</p>
            </div>
            <div>
                <img src="results/cameraman_grad_mag_80.png" alt="Threshold 80">
                <p class="caption">Threshold = 80 (optimal)</p>
            </div>
            <div>
                <img src="results/cameraman_grad_mag_100.png" alt="Threshold 100">
                <p class="caption">Threshold = 100 (too sparse)</p>
            </div>
        </div>

        <h3>Part 1.3: Derivative of Gaussian (DoG) Filter</h3>
        <p>
            The results with just the difference operator were rather noisy. We can improve this by first smoothing the image with a Gaussian filter before computing derivatives.
        </p>


        <h4>Filter Visualization</h4>
        <div class="filter-display">
            <div>
                <img src="results/gaussian_2d_filter.png" alt="2D Gaussian filter">
                <p class="caption">2D Gaussian Filter</p>
            </div>
            <div>
                <img src="results/DoG_x_filter.png" alt="DoG X filter">
                <p class="caption">DoG X Filter</p>
            </div>
            <div>
                <img src="results/DoG_y_filter.png" alt="DoG Y filter">
                <p class="caption">DoG Y Filter</p>
            </div>
        </div>

        <h4>Comparison: Sequential vs Single Convolution</h4>
        <div class="image-comparison">
            <div>
                <img src="results/cameraman_smooth_grad_mag.png" alt="Sequential convolution result">
                <p class="caption">Sequential Convolution<br>(Gaussian → Derivative)</p>
            </div>
            <div>
                <img src="results/cameraman_dog_grad_mag.png" alt="DoG convolution result">
                <p class="caption">Single Convolution<br>(Derivative of Gaussian)</p>
            </div>
        </div>

        <p>
            <strong>Key Observations:</strong> The DoG approach produces much cleaner edge detection with reduced noise compared to the raw finite difference operators. Both the sequential and single convolution approaches produce identical results, demonstrating the associative property of convolution.
        </p>

        <h2>Part 2: Fun with Frequencies!</h2>

        <h3>Part 2.1: Image "Sharpening"</h3>
        <p>
            We can "sharpen" images using the unsharp masking technique. The idea is to subtract a blurred (low-pass filtered) version from the original to extract high frequencies, then add these high frequencies back to enhance sharpness.
        </p>

        <p>
            The unsharp mask filter can be expressed as: <strong>f_sharp = f + α(f - f_blurred) = (1 + α)f - αf_blurred</strong>
        </p>


        <h4>Sharpening Results on Taj Mahal</h4>
        <div class="image-grid">
            <div>
                <img src="taj.jpg" alt="Original Taj">
                <p class="caption">Original Image</p>
            </div>
            <div>
                <img src="results/taj_0.5_unsharp_mask.png" alt="Taj alpha=0.5">
                <p class="caption">α = 0.5 (subtle sharpening)</p>
            </div>
            <div>
                <img src="results/taj_2_unsharp_mask.png" alt="Taj alpha=2">
                <p class="caption">α = 2 (moderate sharpening)</p>
            </div>
            <div>
                <img src="results/taj_4_unsharp_mask.png" alt="Taj alpha=4">
                <p class="caption">α = 4 (strong sharpening)</p>
            </div>
        </div>

        <h4>Sharpening Results on Blurry Guy</h4>
        <div class="image-grid">
            <div>
                <img src="blurry_guy.jpg" alt="Original blurry guy">
                <p class="caption">Original Blurry Image</p>
            </div>
            <div>
                <img src="results/blurry_guy_1_unsharp_mask.png" alt="Blurry guy alpha=1">
                <p class="caption">α = 1 (moderate sharpening)</p>
            </div>
            <div>
                <img src="results/blurry_guy_2_unsharp_mask.png" alt="Blurry guy alpha=2">
                <p class="caption">α = 2 (strong sharpening)</p>
            </div>
            <div>
                <img src="results/blurry_guy_4_unsharp_mask.png" alt="Blurry guy alpha=4">
                <p class="caption">α = 4 (very strong sharpening)</p>
            </div>
        </div>

        <h4>Evaluation: Sharp → Blur → Sharpen</h4>
        <p>
            To evaluate the effectiveness of unsharp masking, we took a sharp image (bird), artificially blurred it, then attempted to sharpen it again:
        </p>

        <div class="image-comparison">
            <div>
                <img src="bird.jpg" alt="Original sharp bird">
                <p class="caption">Original Sharp Image</p>
            </div>
            <div>
                <img src="results/bird_blurred.png" alt="Artificially blurred bird">
                <p class="caption">Artificially Blurred</p>
            </div>
        </div>

        <div class="image-comparison">
            <div>
                <img src="results/bird_blurred.png" alt="Blurred bird">
                <p class="caption">Blurred Version</p>
            </div>
            <div>
                <img src="results/bird_blurred_unsharp_mask.png" alt="Re-sharpened bird">
                <p class="caption">After Unsharp Masking (α = 4)</p>
            </div>
        </div>

        <p>
            <strong>Observations:</strong> While unsharp masking can enhance the perception of sharpness by emphasizing edges and high-frequency details, it cannot fully recover information that was lost during the blurring process. The re-sharpened image shows enhanced edges but cannot match the fine detail of the original sharp image. This demonstrates the fundamental limitation that frequency domain processing cannot create information that wasn't originally present.
        </p>

        <h2>Conclusions</h2>
        <p>
            This project provided hands-on experience with fundamental concepts in image processing:
        </p>
        <ul>
            <li><strong>Convolution Implementation:</strong> Built intuition about 2D convolution through manual implementation, understanding the importance of kernel flipping and proper padding.</li>
            <li><strong>Edge Detection:</strong> Explored finite difference operators and learned how Gaussian smoothing can reduce noise in derivative-based edge detection.</li>
            <li><strong>Frequency Domain Processing:</strong> Demonstrated how unsharp masking can enhance perceived sharpness by manipulating frequency content, while understanding its limitations.</li>
        </ul>
        <p>
            The progression from basic filtering to frequency manipulation illustrates the power and versatility of convolution-based image processing techniques.
        </p>
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/prism.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-python.min.js"></script>
</body>
</html>
