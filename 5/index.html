<!DOCTYPE html>
<html>
<head>
    <title>Project 5: Diffusion Models</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
            color: #333;
        }

        h1, h2, h3, h4 {
            color: #2c3e50;
            margin-top: 30px;
        }

        h1 {
            text-align: center;
            border-bottom: 2px solid #2c3e50;
            padding-bottom: 10px;
        }

        .container {
            background-color: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            margin-bottom: 30px;
        }

        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 20px auto;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }

        .image-row {
            display: flex;
            justify-content: center;
            flex-wrap: wrap;
            gap: 15px;
            margin: 20px 0;
        }

        .image-row img {
            flex: 0 1 auto;
            width: 120px;
            height: 120px;
            margin: 0;
            image-rendering: auto;
        }

        .image-row.large img {
            width: 180px;
            height: 180px;
        }

        .image-comparison {
            display: flex;
            justify-content: space-between;
            margin: 20px 0;
            flex-wrap: wrap;
            gap: 20px;
        }

        .image-comparison > div {
            flex: 0 1 48%;
            margin-bottom: 20px;
        }

        .image-comparison img {
            width: 100%;
        }

        .single-image {
            text-align: center;
            margin: 30px 0;
        }

        .single-image img {
            width: 256px;
            height: 256px;
            image-rendering: auto;
        }

        .caption {
            text-align: center;
            font-style: italic;
            margin: 10px 0;
            color: #666;
        }

        code {
            background-color: #f8f9fa;
            padding: 2px 5px;
            border-radius: 3px;
            font-family: 'Courier New', Courier, monospace;
        }

        .section-divider {
            margin: 40px 0;
            border-top: 2px solid #e0e0e0;
        }

        .grid-3 {
            display: grid;
            grid-template-columns: repeat(3, 200px);
            justify-content: center;
            gap: 20px;
            margin: 20px 0;
        }

        .grid-3 img {
            width: 200px;
            height: 200px;
            margin: 0;
            image-rendering: auto;
        }

        .grid-2 {
            display: grid;
            grid-template-columns: repeat(2, 250px);
            justify-content: center;
            gap: 30px;
            margin: 20px 0;
        }

        .grid-2 img {
            width: 250px;
            height: 250px;
            margin: 0;
            image-rendering: auto;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Project 5: Diffusion Models</h1>

        <h2>Overview</h2>
        <p>
            This project explores diffusion models for image generation, using the DeepFloyd IF model.
            Diffusion models work by iteratively denoising images, starting from pure noise and gradually
            refining them into coherent images guided by text prompts.
        </p>

        <div class="section-divider"></div>

        <h2>Part 0: Setup</h2>
        <p>
            The project uses DeepFloyd IF, a two-stage diffusion model. Stage 1 generates 64x64 images,
            and Stage 2 upscales to 256x256. For this project, we focus on Stage 1.
        </p>
        <p>
            <strong>Seed used:</strong> <code>100</code>
        </p>
        <p>
            Sample outputs from the pretrained model with my custom prompts (num_inference_steps=20):
        </p>
        <div class="grid-3">
            <div>
                <img src="media/03___Get_prompt_embeddings_from_the_co_0.png" alt="Cosmic black hole">
                <p class="caption">"a cosmic black hole consuming a swirling galaxy"</p>
            </div>
            <div>
                <img src="media/04___Get_prompt_embeddings_from_the_co_1.png" alt="Cyberpunk alleyway">
                <p class="caption">"a neon-lit cyberpunk alleyway in pouring rain"</p>
            </div>
            <div>
                <img src="media/05___Get_prompt_embeddings_from_the_co_2.png" alt="Floating temple">
                <p class="caption">"a floating ancient temple among sunset clouds"</p>
            </div>
        </div>

        <h4>Effect of num_inference_steps</h4>
        <p>
            Comparing the first prompt with different inference steps:
        </p>
        <div class="grid-2">
            <div>
                <img src="media/00___Get_prompt_embeddings_from_the_co_0.png" alt="20 steps">
                <p class="caption">num_inference_steps=20</p>
            </div>
            <div>
                <img src="media/06___Get_prompt_embeddings_from_the_co_0.png" alt="50 steps">
                <p class="caption">num_inference_steps=50</p>
            </div>
        </div>
        <p>
            <strong>Reflection:</strong> The outputs capture the essence of the prompts well - the black hole shows swirling galactic structures, the cyberpunk alley has neon lighting and rain effects, and the temple floats among clouds. With more inference steps (50 vs 20), the galaxy more clearly displays the "swallowing" of the galaxy by the black hole.
        </p>

        <div class="section-divider"></div>

        <h2>Part 1: Sampling Loops</h2>

        <h3>1.1 Implementing the Forward Process</h3>
        <p>
            The forward process adds noise to a clean image according to the diffusion schedule.
            Given a clean image x<sub>0</sub>, we can obtain a noisy image at timestep t using:
        </p>
        <p style="text-align: center;">
            <code>x_t = sqrt(alpha_bar_t) * x_0 + sqrt(1 - alpha_bar_t) * epsilon</code>
        </p>
        <p>where epsilon is Gaussian noise and alpha_bar_t is the cumulative product of noise schedule alphas.</p>

        <h4>Test Image at Different Noise Levels</h4>
        <div class="image-row large">
            <img src="media/07___Get_test_image_0.png" alt="Original test image">
            <img src="media/09___Show_the_test_image_at_noise_leve_1.png" alt="Noise level 250">
            <img src="media/10___Show_the_test_image_at_noise_leve_2.png" alt="Noise level 500">
            <img src="media/11___Show_the_test_image_at_noise_leve_3.png" alt="Noise level 750">
        </div>
        <p class="caption">Original image, then with noise at t=250, t=500, t=750</p>

        <h3>1.2 Classical Denoising</h3>
        <p>
            As a baseline, we try denoising with Gaussian blur. This approach fails because
            blur cannot recover the high-frequency details lost to noise.
        </p>
        <div class="image-row large">
            <img src="media/12___Classical_denoising_with_Gaussian_0.png" alt="Noisy at t=250">
            <img src="media/13___Classical_denoising_with_Gaussian_1.png" alt="Blurred t=250">
            <img src="media/14___Classical_denoising_with_Gaussian_2.png" alt="Noisy at t=500">
            <img src="media/15___Classical_denoising_with_Gaussian_3.png" alt="Blurred t=500">
            <img src="media/16___Classical_denoising_with_Gaussian_4.png" alt="Noisy at t=750">
            <img src="media/17___Classical_denoising_with_Gaussian_5.png" alt="Blurred t=750">
        </div>
        <p class="caption">Noisy images and their Gaussian-blurred versions at t=250, 500, 750</p>

        <h3>1.3 One-Step Denoising</h3>
        <p>
            Using the UNet to estimate and remove noise in a single step with a null prompt embedding.
            While better than Gaussian blur, one-step denoising still produces blurry results,
            especially at higher noise levels.
        </p>
        <div class="grid-3">
            <div>
                <img src="media/19___Please_use_the_null_prompt_embedd_1.png" alt="One-step t=250">
                <p class="caption">One-step denoise from t=250</p>
            </div>
            <div>
                <img src="media/22___Please_use_the_null_prompt_embedd_1.png" alt="One-step t=500">
                <p class="caption">One-step denoise from t=500</p>
            </div>
            <div>
                <img src="media/25___Please_use_the_null_prompt_embedd_1.png" alt="One-step t=750">
                <p class="caption">One-step denoise from t=750</p>
            </div>
        </div>

        <h3>1.4 Iterative Denoising</h3>
        <p>
            Iterative denoising gradually removes noise over multiple steps using strided timesteps.
            Starting from timestep 690, we denoise through 30 steps with stride 30.
        </p>
        <div class="image-row">
            <img src="media/27_def_iterative_denoise_im_noisy__i_s_0.png" alt="Step 0">
            <img src="media/28_def_iterative_denoise_im_noisy__i_s_1.png" alt="Step 5">
            <img src="media/29_def_iterative_denoise_im_noisy__i_s_2.png" alt="Step 10">
            <img src="media/30_def_iterative_denoise_im_noisy__i_s_3.png" alt="Step 15">
            <img src="media/31_def_iterative_denoise_im_noisy__i_s_4.png" alt="Step 20">
        </div>
        <p class="caption">Denoising progress at every 5th step</p>

        <div class="image-row large">
            <div style="text-align: center;">
                <img src="media/32_def_iterative_denoise_im_noisy__i_s_0.png" alt="Original">
                <p class="caption">Original</p>
            </div>
            <div style="text-align: center;">
                <img src="media/33_def_iterative_denoise_im_noisy__i_s_1.png" alt="Iterative result">
                <p class="caption">Iterative Denoise</p>
            </div>
            <div style="text-align: center;">
                <img src="media/34_def_iterative_denoise_im_noisy__i_s_2.png" alt="One-step result">
                <p class="caption">One-Step Denoise</p>
            </div>
            <div style="text-align: center;">
                <img src="media/35_def_iterative_denoise_im_noisy__i_s_3.png" alt="Gaussian blur">
                <p class="caption">Gaussian Blur</p>
            </div>
        </div>

        <h3>1.5 Diffusion Model Sampling</h3>
        <p>
            By starting from pure noise (t=990) and iteratively denoising, we can generate new images.
            Using the prompt <code>"a high quality photo"</code>:
        </p>
        <div class="image-row large">
            <img src="media/36___Please_use_this_text_prompt_0.png" alt="Sample 1">
            <img src="media/37___Please_use_this_text_prompt_1.png" alt="Sample 2">
            <img src="media/38___Please_use_this_text_prompt_2.png" alt="Sample 3">
            <img src="media/39___Please_use_this_text_prompt_3.png" alt="Sample 4">
            <img src="media/40___Please_use_this_text_prompt_4.png" alt="Sample 5">
        </div>
        <p class="caption">5 samples generated with "a high quality photo"</p>

        <h3>1.6 Classifier-Free Guidance (CFG)</h3>
        <p>
            CFG improves sample quality by combining conditional and unconditional noise estimates:
        </p>
        <p style="text-align: center;">
            <code>epsilon = epsilon_uncond + gamma * (epsilon_cond - epsilon_uncond)</code>
        </p>
        <p>Using gamma=7 with prompt <code>"a high quality photo"</code> produces higher quality images:</p>
        <div class="image-row large">
            <img src="media/41___The_conditional_prompt_embedding_0.png" alt="CFG Sample 1">
            <img src="media/42___The_conditional_prompt_embedding_1.png" alt="CFG Sample 2">
            <img src="media/43___The_conditional_prompt_embedding_2.png" alt="CFG Sample 3">
            <img src="media/44___The_conditional_prompt_embedding_3.png" alt="CFG Sample 4">
            <img src="media/45___The_conditional_prompt_embedding_4.png" alt="CFG Sample 5">
        </div>
        <p class="caption">5 samples with CFG (gamma=7) and "a high quality photo"</p>

        <h3>1.7 Image-to-Image Translation (SDEdit)</h3>
        <p>
            SDEdit adds noise to an existing image and then denoises it. By controlling how much noise
            is added (via the starting index i_start), we can balance between faithfulness to the original
            and creative freedom. Using prompt <code>"a high quality photo"</code>:
        </p>

        <h4>SDEdit on Test Image (Campanile)</h4>
        <div class="image-row">
            <img src="media/46___The_conditional_prompt_embedding_0.png" alt="i_start=1">
            <img src="media/47___The_conditional_prompt_embedding_1.png" alt="i_start=3">
            <img src="media/48___The_conditional_prompt_embedding_2.png" alt="i_start=5">
            <img src="media/49___The_conditional_prompt_embedding_3.png" alt="i_start=7">
            <img src="media/50___The_conditional_prompt_embedding_4.png" alt="i_start=10">
            <img src="media/51___The_conditional_prompt_embedding_5.png" alt="i_start=20">
            <img src="media/52___The_conditional_prompt_embedding_6.png" alt="Original">
        </div>
        <p class="caption">SDEdit results with i_start: 1, 3, 5, 7, 10, 20, and original</p>

        <h4>SDEdit on My Own Images</h4>
        <p><strong>Lighthouse:</strong></p>
        <div class="image-row">
            <img src="media/53___SDEdit_on_your_own_image_1__IMG_2_0.png" alt="i_start=1">
            <img src="media/54___SDEdit_on_your_own_image_1__IMG_2_1.png" alt="i_start=3">
            <img src="media/55___SDEdit_on_your_own_image_1__IMG_2_2.png" alt="i_start=5">
            <img src="media/56___SDEdit_on_your_own_image_1__IMG_2_3.png" alt="i_start=7">
            <img src="media/57___SDEdit_on_your_own_image_1__IMG_2_4.png" alt="i_start=10">
            <img src="media/58___SDEdit_on_your_own_image_1__IMG_2_5.png" alt="i_start=20">
            <img src="media/59___SDEdit_on_your_own_image_1__IMG_2_6.png" alt="Original">
        </div>

        <p><strong>Lake:</strong></p>
        <div class="image-row">
            <img src="media/60___SDEdit_on_your_own_image_2__IMG_2_0.png" alt="i_start=1">
            <img src="media/61___SDEdit_on_your_own_image_2__IMG_2_1.png" alt="i_start=3">
            <img src="media/62___SDEdit_on_your_own_image_2__IMG_2_2.png" alt="i_start=5">
            <img src="media/63___SDEdit_on_your_own_image_2__IMG_2_3.png" alt="i_start=7">
            <img src="media/64___SDEdit_on_your_own_image_2__IMG_2_4.png" alt="i_start=10">
            <img src="media/65___SDEdit_on_your_own_image_2__IMG_2_5.png" alt="i_start=20">
            <img src="media/66___SDEdit_on_your_own_image_2__IMG_2_6.png" alt="Original">
        </div>

        <h4>1.7.1 Editing Hand-Drawn and Web Images</h4>
        <p>
            SDEdit works particularly well for projecting non-realistic images (sketches, paintings)
            onto the natural image manifold. Using prompt <code>"a high quality photo"</code>:
        </p>

        <p><strong>Web Image:</strong></p>
        <div class="image-row">
            <img src="media/68_prompt_embeds___prompt_embeds_dict__0.png" alt="i_start=1">
            <img src="media/69_prompt_embeds___prompt_embeds_dict__1.png" alt="i_start=3">
            <img src="media/70_prompt_embeds___prompt_embeds_dict__2.png" alt="i_start=5">
            <img src="media/71_prompt_embeds___prompt_embeds_dict__3.png" alt="i_start=7">
            <img src="media/72_prompt_embeds___prompt_embeds_dict__4.png" alt="i_start=10">
            <img src="media/73_prompt_embeds___prompt_embeds_dict__5.png" alt="i_start=20">
        </div>

        <p><strong>Hand-Drawn Image 1:</strong></p>
        <div class="image-row">
            <img src="media/74____title_Hand_Drawn_Image_1_0.png" alt="Hand-drawn 1">
        </div>
        <div class="image-row">
            <img src="media/75___Process_Hand_Drawn_Image_1_0.png" alt="i_start=1">
            <img src="media/76___Process_Hand_Drawn_Image_1_1.png" alt="i_start=3">
            <img src="media/77___Process_Hand_Drawn_Image_1_2.png" alt="i_start=5">
            <img src="media/78___Process_Hand_Drawn_Image_1_3.png" alt="i_start=7">
            <img src="media/79___Process_Hand_Drawn_Image_1_4.png" alt="i_start=10">
            <img src="media/80___Process_Hand_Drawn_Image_1_5.png" alt="i_start=20">
        </div>

        <p><strong>Hand-Drawn Image 2:</strong></p>
        <div class="image-row">
            <img src="media/81____title_Hand_Drawn_Image_2_0.png" alt="Hand-drawn 2">
        </div>
        <div class="image-row">
            <img src="media/82___Process_Hand_Drawn_Image_2_0.png" alt="i_start=1">
            <img src="media/83___Process_Hand_Drawn_Image_2_1.png" alt="i_start=3">
            <img src="media/84___Process_Hand_Drawn_Image_2_2.png" alt="i_start=5">
            <img src="media/85___Process_Hand_Drawn_Image_2_3.png" alt="i_start=7">
            <img src="media/86___Process_Hand_Drawn_Image_2_4.png" alt="i_start=10">
            <img src="media/87___Process_Hand_Drawn_Image_2_5.png" alt="i_start=20">
        </div>

        <h4>1.7.2 Inpainting</h4>
        <p>
            Inpainting fills in masked regions of an image while keeping the rest intact.
            At each denoising step, we replace non-masked regions with the properly noised original.
        </p>

        <p><strong>Campanile:</strong></p>
        <div class="grid-3">
            <div>
                <img src="media/88___Inpainting_the_Campanile_0.png" alt="Original">
                <p class="caption">Original</p>
            </div>
            <div>
                <img src="media/90___Inpainting_the_Campanile_2.png" alt="Mask">
                <p class="caption">Mask</p>
            </div>
            <div>
                <img src="media/93___Inpainting_the_Campanile_2.png" alt="Inpainted">
                <p class="caption">Inpainted</p>
            </div>
        </div>

        <p><strong>Waterfall:</strong></p>
        <div class="grid-3">
            <div>
                <img src="media/94___Inpainting_Image_1__IMG_2709_png__0.png" alt="Original">
                <p class="caption">Original</p>
            </div>
            <div>
                <img src="media/96___Inpainting_Image_1__IMG_2709_png__2.png" alt="Mask">
                <p class="caption">Mask</p>
            </div>
            <div>
                <img src="media/99___Inpainting_Image_1__IMG_2709_png__2.png" alt="Inpainted">
                <p class="caption">Inpainted</p>
            </div>
        </div>

        <p><strong>Bat:</strong></p>
        <div class="grid-3">
            <div>
                <img src="media/100___Inpainting_Image_2__IMG_3146_png__0.png" alt="Original">
                <p class="caption">Original</p>
            </div>
            <div>
                <img src="media/102___Inpainting_Image_2__IMG_3146_png__2.png" alt="Mask">
                <p class="caption">Mask</p>
            </div>
            <div>
                <img src="media/105___Inpainting_Image_2__IMG_3146_png__2.png" alt="Inpainted">
                <p class="caption">Inpainted</p>
            </div>
        </div>

        <h4>1.7.3 Text-Conditional Image-to-Image Translation</h4>
        <p>
            Combining SDEdit with text prompts to guide the transformation.
        </p>

        <p><strong>Campanile with prompt "a rocket ship":</strong></p>
        <div class="image-row">
            <img src="media/106___Text_Conditioned_Image_to_image_o_0.png" alt="i_start=1">
            <img src="media/107___Text_Conditioned_Image_to_image_o_1.png" alt="i_start=3">
            <img src="media/108___Text_Conditioned_Image_to_image_o_2.png" alt="i_start=5">
            <img src="media/109___Text_Conditioned_Image_to_image_o_3.png" alt="i_start=7">
            <img src="media/110___Text_Conditioned_Image_to_image_o_4.png" alt="i_start=10">
            <img src="media/111___Text_Conditioned_Image_to_image_o_5.png" alt="i_start=20">
            <img src="media/112___Text_Conditioned_Image_to_image_o_6.png" alt="Original">
        </div>
        <p class="caption">i_start: 1, 3, 5, 7, 10, 20, and original</p>

        <p><strong>Image of city with prompt "a neon-lit cyberpunk alleyway in pouring rain":</strong></p>
        <div class="image-row">
            <img src="media/113___Text_Conditioned_Image_to_image_o_0.png" alt="i_start=1">
            <img src="media/114___Text_Conditioned_Image_to_image_o_1.png" alt="i_start=3">
            <img src="media/115___Text_Conditioned_Image_to_image_o_2.png" alt="i_start=5">
            <img src="media/116___Text_Conditioned_Image_to_image_o_3.png" alt="i_start=7">
            <img src="media/117___Text_Conditioned_Image_to_image_o_4.png" alt="i_start=10">
            <img src="media/118___Text_Conditioned_Image_to_image_o_5.png" alt="i_start=20">
            <img src="media/119___Text_Conditioned_Image_to_image_o_6.png" alt="Original">
        </div>

        <p><strong>Image of trees with prompt "an oil painting of an elderly bearded wizard":</strong></p>
        <div class="image-row">
            <img src="media/120___Text_Conditioned_Image_to_image_o_0.png" alt="i_start=1">
            <img src="media/121___Text_Conditioned_Image_to_image_o_1.png" alt="i_start=3">
            <img src="media/122___Text_Conditioned_Image_to_image_o_2.png" alt="i_start=5">
            <img src="media/123___Text_Conditioned_Image_to_image_o_3.png" alt="i_start=7">
            <img src="media/124___Text_Conditioned_Image_to_image_o_4.png" alt="i_start=10">
            <img src="media/125___Text_Conditioned_Image_to_image_o_5.png" alt="i_start=20">
            <img src="media/126___Text_Conditioned_Image_to_image_o_6.png" alt="Original">
        </div>

        <div class="section-divider"></div>

        <h2>Part 1.8: Visual Anagrams</h2>
        <p>
            Visual anagrams are images that look like one thing right-side up and another thing upside down.
            We create these by averaging noise estimates from two different prompts, one applied to the
            flipped image:
        </p>
        <p style="text-align: center;">
            <code>epsilon_1 = CFG(UNet(x_t, t, p1))</code><br>
            <code>epsilon_2 = flip(CFG(UNet(flip(x_t), t, p2)))</code><br>
            <code>epsilon = (epsilon_1 + epsilon_2) / 2</code>
        </p>

        <p><strong>Illusion 1: Wizard / Tree</strong></p>
        <div class="grid-2">
            <div>
                <img src="media/127_def_make_flip_illusion_prompt_embed_0.png" alt="Wizard">
                <p class="caption">Normal: "an oil painting of an elderly bearded wizard"</p>
            </div>
            <div>
                <img src="media/128_def_make_flip_illusion_prompt_embed_1.png" alt="Tree">
                <p class="caption">Flipped: "an oil painting of a twisted dead tree"</p>
            </div>
        </div>

        <p><strong>Illusion 2: Mountain / Waves</strong></p>
        <div class="grid-2">
            <div>
                <img src="media/129___Visual_Anagram_Illusion_2__Mounta_0.png" alt="Mountain">
                <p class="caption">Normal: "a watercolor of snowy mountain peaks"</p>
            </div>
            <div>
                <img src="media/130___Visual_Anagram_Illusion_2__Mounta_1.png" alt="Waves">
                <p class="caption">Flipped: "a watercolor of crashing ocean waves"</p>
            </div>
        </div>

        <div class="section-divider"></div>

        <h2>Part 1.9: Hybrid Images</h2>
        <p>
            Hybrid images combine the low frequencies of one image with the high frequencies of another
            using Factorized Diffusion:
        </p>
        <p style="text-align: center;">
            <code>epsilon_1 = CFG(UNet(x_t, t, p1))</code><br>
            <code>epsilon_2 = CFG(UNet(x_t, t, p2))</code><br>
            <code>epsilon = lowpass(epsilon_1) + highpass(epsilon_2)</code>
        </p>
        <p>Using Gaussian blur with kernel size 33 and sigma 2 for the low-pass filter.</p>

        <p><strong>Hybrid 1: Tiger (low freq) + Fire (high freq)</strong></p>
        <div class="single-image">
            <img src="media/131_def_make_hybrids_prompt_embeds_1__p_0.png" alt="Tiger-Fire Hybrid">
            <p class="caption">Low: "a photo of a fierce tiger face" / High: "a photo of blazing orange fire"</p>
        </div>

        <p><strong>Hybrid 2: Moon (low freq) + Eye (high freq)</strong></p>
        <div class="single-image">
            <img src="media/132___Hybrid_Image_2__Moon__low_freq____0.png" alt="Moon-Eye Hybrid">
            <p class="caption">Low: "a painting of a giant full moon" / High: "a painting of a detailed human eye"</p>
        </div>

        <div class="section-divider"></div>
    </div>
</body>
</html>
